# Grundlagen Datenbanken -- 20.01.2016

Es wird gleichzeitig, on-demand (lazily) sowohl bei Build- als auch Probeinput
der Merge (beim Sort/Merge) gemacht, sodass man on-demand jeweils die kleinsten
Elemente beider Seiten hat, und daher den Merge schon machen kann.

Oftmals Sentinel-Node im kleineren Input (z.B. ein Element "unendlich"), dann
wird immer das Element vom anderen Input genommen (ist immer kleiner).

Best-Case von Replacement-Selection ist linear, wenn die Daten schon voll oder
*fast* sortiert sind. Da dann immer groessere Elemente nachgeladen
werden. Deswegen beliebt.

Fragmentierung wegen verschieden grosser Tupeln ist ein
Implementierungsproblem. Also wenn man ein Element in die Ausgabe gibt, und dann
ein neues Element nachladen will, dann muss dieses Element kleiner oder gleich
gross sein (vom Speicherbedarf).

Man braucht als Fallbackloesung troztdem noch nested Loops in jedem
Datenbanksystem, z.B. fuer einen Join $R \bowtie_{A\neq B} S$. Hierbei kann man
keinen exakt-match oder sort machen.

Selektion ist mit linearem Loop besser als mit Index, wenn mehr als $10\%$ der
Daten uebrig bleiben werden.

Duplikateleminierung: Nested Loop fuer $~20$ Elemente, sonst $O(N)$ Hash/Index
oder in manchen Faellen Sort.

IndexJoin manchmal: Index auf groessere Relation, mit kleinerer Relation
durchproben.

Generierung aller denkbaren Anfrageauswertungsplaene ist hyperexponentiell,
z.B. $n!$ wo $n$ die Anzahl der Relationen ist (meistens klein).

Datenbanksysteme haben Statistiken ueber Anfragen, in Form von Histogrammen.

Anfragen werden auch an Rechner bzw. dessen Parallelitaet kalibriert. Und ist
auch vom verfuegbaren Speicher abhaengig.

Aufwands-Kostenmodell ist Aufwands-minimierend, nicht
Antwortzeitminimierend. Also man kann sich nicht fuer eine dringende Anfrage 80
Kerne reservieren. Zum eien, weil die Kerne sich im Wege stehen wuerden.

Catalanische Zahl: $C(n - 1)$

Dann fuer $n$ Relationen (wo die $n$ Relationen noch permutieren koennen):
$C(n - 1) \cdot n!$

Insgesamt Bushy Plaene mit $n$ Tabellen: $\frac{(2(n-1))!}{(n-1)!}$

Man braucht eine Kostenfunktion um die Strategien zu bewerten.

Die Selektivitaet eines Suchpraedikats schaetzt die Anzahl der qualifizierenden
Tupel relativ zur Gesamtanzahl der Tupel. Je kleiner der Wert, desto groesser
die Selektivitaet. $sel_p := \frac{|\sigma_p(R)|}{|R|}$

Fuer Joins von $R$ auf $S$: $sel_{RS} := \frac{|R \bowtie S|}{|R \times S|} =
\frac{|R \bowtie S|}{R \cdot S}$

Bei Selektion mit Fremdschluessel: $sel_{R.A=C} = \frac{1}{|R|} = \frac{|S|}{|R|
\cdot |S|}$

In Histogrammen wird mit ausgebuegelten equi-width Regionen gearbeitet. Gibt
aber auch equi-height Verfahren. Daebi wird ein fester $y$ Wert genommen, und
die Regionen werden so breit (auf $x$-Achse) gemacht, dass jeweils der $y$ Wert
insgesamt erreicht wird (Integral). Man muss die Daten aber auch upgedatet
halten, da man nicht mit gut mit alten Datenabschaetzungen arbeiten kann.

oracle: `analyze table Professoren compute/estimate statistics for table`.

`estimate` probt die Tabelle nur, `compute` berechnet sie vollkommen.

Dynamisches Programmieren fuer DBs ist $3^n$, wegen Assoziativitaet und
Kommutativitaet. Letzteres ist z.B. fuer Matrizen nicht erlaubt, reduziert also
die Moglichkeiten auf $n^3$.

Optimalitaetskriterium = Matroid-Eigenschaft

Man "ratet", wie man die Relationen aufteilt, um sie zu joinen.

Travelling-Salesman Problem nicht mit DP loesbar. Weil man die Teilungen nicht
separat optimieren kann.

Bei Joins kann man die geteilten Relationenmengen unabhaengig von einder
optimieren.

iscan = index-scan

Kommutativitaet ist wichtig. Das Endergebnis des Joins ist zwar das selbe, aber
ein Hash-Join ist z.B. effizienter mit kleinerem Build Input. Oder wenn der
Probe schon sortiert ist, kommen beim Hash Join auch sortierte Tupel raus.

$2^n - 1$ Moeglichkeiten fuer $n$ Relationen ($-1$ weil nicht leer).

Kreuzprodukt gut wenn die Relationen klein sind.

Standardmaessig ist jeder Befehl eine Transaktion. Normallerweise ist
"autocommit" ein, also wird jeder Befehl committet. Aber man kann es
ausschalten. Dann muss man manuell committen. Oder kann auch "rollback" machen
(abort). Atomare Operation.

Es gibt noch zwischen BOT und Ende sogenannte savepoints (`define savepoint`)
wie Checkpoints in Spielen. Dann kann man immer zu einem dieser savepoints
zurueck (quasi partial savepoint).


Transaktionen muessen atomar sein. Die Transaktion muss entweder durch ein
commit oder abort abgeschlossen werden. Nie Seiteneffekte davor!!


ACID:

* Atomicity (Atomaritaet): Succeed completely or fail completely
* Consistensy: Aus einem konsistenten Zustand muss ein schlussendlich ein
  konsistenter Zustand erfolgen. Dazwischen darf er inkonsistent sein.
* Isolation: Jede Transaktion ist isoliert von anderen -- als ob es die einzige
  waere.
* Durability (Dauerhaftigkeit): Aenderungen erfolgreicher Transaktionen duerfen
  nie verloren gehen.

Transaktion die vor einem Absturz committet wurde: Winner
Transaktion die noch nicht committet wurde: Loser

commit work = commit ohne ende der transaktion
rollback work = rollback ohne ende der transaktion

Temporaere Inkonsistenzen erlaubt, weil sonst zyklische Abhaengigkeiten nicht
eingefuegt werden koennten.
